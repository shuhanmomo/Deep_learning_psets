{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first term, $\\mathbb{E}_{q\\phi(z|x)}[\\log p_\\theta(x|z)]$, encourages the model to reconstruct the input $x$ accurately from the latent variable $z$. The second term, $D_{\\mathrm{KL}}(q_\\phi(z|x) || p(z))$, regularizes the encoder by pushing $q_\\phi(z|x)$ towards the prior $p(z)$, typically making the latent space resemble a standard normal distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding only the means of the embeddings is insufficient to recover the data distribution because the variances $\\sigma_z^2$ are crucial for capturing the full variability of the data. Both the means $\\mu_z$ and variances $\\sigma_z^2$ are necessary to sample latent variables $z \\sim q_\\phi(z|x)$, which the decoder uses to reconstruct $x$ and accurately represent the data distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder produces $ q_\\phi(z|x) = \\mathcal{N}(z; f^\\mu_\\phi(x), f^\\sigma_\\phi(x)) $. The marginal distribution $ q_\\phi(z) $ is obtained by integrating over the data distribution: $ q_\\phi(z) = \\int q_\\phi(z|x) \\, p_{\\text{data}}(x) \\, dx $. Even if $ q_\\phi(z) $ is a unit Gaussian, this doesn't imply that the means $ f^\\mu_\\phi(x) $ are Gaussian distributed.For example,as Central Limit Theorem (CLT) describes, sums of independent random variables tend to become Gaussian regardless of their original distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No. Since the autoencoder only minimizes reconstruction error without constraining the latent space, the encoded $ z = f(x) $ does not necessarily follow a standard normal distribution; therefore, decoding $ z \\sim \\mathcal{N}(0, I) $ with $ g $ won't reproduce the data distribution $ p_{\\text{data}} $.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VAE**\n",
    "\n",
    "```python\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, z_dims=4, input_size=784, num_hidden=128):\n",
    "        super().__init__()\n",
    "        self.z_dims = z_dims\n",
    "        self.input_size = input_size\n",
    "\n",
    "        # FIXME: Create two encoder layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, num_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden, num_hidden),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # FIXME: Create the mean and logvar readout layers\n",
    "        self.mu = nn.Linear(num_hidden, z_dims)\n",
    "        self.logvar = nn.Linear(num_hidden, z_dims)\n",
    "\n",
    "        # FIXME: Create the decoder layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(z_dims, num_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden, num_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden, input_size),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # FIXME: Implement the VAE forward function\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.encoder(x)\n",
    "        mu = self.mu(x)\n",
    "        logvar = self.logvar(x)\n",
    "        # reparameterization trick\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        epsilon = torch.randn_like(std)\n",
    "        z = mu + std * epsilon\n",
    "        output = self.decoder(z)\n",
    "        return output, mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Script**\n",
    "```python\n",
    "model = VAE().cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for X, _ in tqdm(train_loader):\n",
    "        X = X.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        x_prime, mu, logvar = model(X)\n",
    "\n",
    "        # FIXME: Calculate loss\n",
    "        reconstruction_loss = F.mse_loss(\n",
    "            x_prime, X.flatten(start_dim=1), reduction=\"sum\"\n",
    "        )\n",
    "        kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        # negative ELBO\n",
    "        loss = reconstruction_loss + kl_divergence\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\n",
    "        \"Epoch: {} Train Loss: {:.4f}\".format(\n",
    "            epoch, train_loss / len(train_loader.dataset)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**plot latent space**\n",
    "```python\n",
    "def plot_latents(model, i=0, j=1):\n",
    "    # FIXME: Plot the image grid\n",
    "    model.eval()\n",
    "    n = 10  # 280*280\n",
    "    grid_x = np.linspace(-2, 2, n)\n",
    "    grid_y = np.linspace(-2, 2, n)\n",
    "\n",
    "    digit_size = 28\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "\n",
    "    for xi, x in enumerate(grid_x):\n",
    "        for yi, y in enumerate(grid_y):\n",
    "            z = torch.zeros(model.z_dims)\n",
    "            z[i] = x\n",
    "            z[j] = y\n",
    "            z = z.unsqueeze(0).to(next(model.parameters()).device)\n",
    "            with torch.no_grad():\n",
    "                x_decoded = model.decoder(z)\n",
    "            x_decoded = x_decoded.cpu().numpy().reshape(digit_size, digit_size)\n",
    "            figure[\n",
    "                (n - yi - 1) * digit_size : (n - yi) * digit_size,\n",
    "                xi * digit_size : (xi + 1) * digit_size,\n",
    "            ] = x_decoded\n",
    "\n",
    "    # Plot the big image\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(figure, cmap=\"gray\")\n",
    "    plt.xlabel(f\"Latent dimension {i}\")\n",
    "    plt.ylabel(f\"Latent dimension {j}\")\n",
    "    plt.title(f\"Latent space traversal for dimensions {i} and {j}\")\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
